paths: {
    data_path: "/media/rosu/Data/data"
}

core: {
    loguru_verbosity: 3
    hidpi: true
    debug_with_profiler: true //makes the profiler print when it starts and stops time
}


loader_shapenet_partseg: {
    dataset_path: "/media/rosu/Data/data/shapenet_part_seg/shapenet_part_seg/shapenetcore_partanno_segmentation_benchmark_v0"
    // dataset_path: "/home/local/staff/rosu/data/shapenet_part_seg/shapenet_part_seg/shapenetcore_partanno_segmentation_benchmark_v0"
    autostart: false
    mode: "train" // train, test, val
    restrict_to_object: "airplane" // you can leave it empty to get all of them or write any of (airplane, bag, cap, car, chair, earphone, guitar, knife, lamp, laptop, motorbike, mug, pistol, rocket, skateboard, table)
    shuffle_points: true
    normalize: false // normalize the point cloud between [-1 and 1]
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset

    // label_mngr: {

    //     //motorbike
    //     labels_file: "/media/rosu/Data/data/shapenet_part_seg/motorbike/labels.txt"
    //     color_scheme_file: "/media/rosu/Data/data/shapenet_part_seg/motorbike/color_scheme.txt"
    //     frequency_file: "/media/rosu/Data/data/shapenet_part_seg/motorbike/frequency.txt"

    //     // // knife
    //     // labels_file: "/media/rosu/Data/data/shapenet_part_seg/knife/labels.txt"
    //     // color_scheme_file: "/media/rosu/Data/data/shapenet_part_seg/knife/color_scheme.txt"
    //     // frequency_file: "/media/rosu/Data/data/shapenet_part_seg/knife/frequency.txt"

    //     // // bag
    //     // labels_file: "/media/rosu/Data/data/shapenet_part_seg/bag/labels.txt"
    //     // color_scheme_file: "/media/rosu/Data/data/shapenet_part_seg/bag/color_scheme.txt"
    //     // frequency_file: "/media/rosu/Data/data/shapenet_part_seg/bag/frequency.txt"


    //     unlabeled_idx: 0
    // }

    // one used for actual augmentation
    transformer: {
        random_translation_xyz_magnitude: 0.0
        random_translation_xz_magnitude: 0.2
        rotation_y_max_angle: 0.0
        // random_stretch_xyz_magnitude: 0.2
        random_stretch_xyz_magnitude: 0.0
        adaptive_subsampling_falloff_start: 0.0
        adaptive_subsampling_falloff_end: 0.0
        // random_subsample_percentage: 0.998 //randomly removed x percent of the pointcloud
        random_subsample_percentage: 0.0 //randomly removed x percent of the pointcloud
        random_mirror_x: false
        random_mirror_z: true
        random_rotation_90_degrees_y: false

        hsv_jitter:[0,0,0]

        chance_of_xyz_noise: 0.0
        xyz_noise_stddev: [0.0, 0.0, 0.0]
    }
}


loader_vol_ref: {
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/augustus-ps"
    dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/lucy-ps"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/sokrates-ps"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/figure-mvs"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/sokrates-mvs"
    // dataset_path: "/media/rosu/Data/data/volumetric_refienement_data/vase-mvs"
    autostart: false
    preload: true //preload the meshes in memory which is usually quite fast if they are small, or continously read them from memory

    nr_samples_to_skip: 0
    nr_samples_to_read: -1
    shuffle: false
    rgb_subsample_factor: 4
    depth_subsample_factor: 4
    load_rgb_with_valid_depth: true
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset

    scene_translation: [0.1, -0.1, 1.2]
    scene_scale_multiplier: 1.0


}

loader_stanford_3D_scene: {
    // dataset_path: "/media/rosu/Data/data/stanford_3D_scene/data/copyroom/copyroom_png-002"
    // pose_file_path: "/media/rosu/Data/data/stanford_3D_scene/data/copyroom/copyroom-20200504T192457Z-001/copyroom/copyroom_trajectory.log"
    dataset_path: "/media/rosu/Data/data/stanford_3D_scene/data/totempole/totempole_png-003"
    pose_file_path: "/media/rosu/Data/data/stanford_3D_scene/data/totempole/totempole-20200504T222429Z-001/totempole/totempole_trajectory.log"
    // dataset_path: "/media/alex/22223740223717ED/data/totempole/totempole_png-003"
    // pose_file_path: "/media/alex/22223740223717ED/data/totempole/totempole-20200504T222429Z-001/totempole/totempole_trajectory.log"
    autostart: false
    nr_samples_to_skip: 0
    nr_samples_to_read: -1
    shuffle: false
    rgb_subsample_factor: 1
    depth_subsample_factor: 4
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset

}

loader_img: {
    autostart: false
    nr_cams: 1
    rgb_path_cam_0: "/media/rosu/Data/phd/c_ws/src/phenorob/vae_from_others/VAE/data"
    imgs_to_skip: 0
    nr_images_to_read: -1
    only_rgb: true
    rgb_subsample_factor: 1
    shuffle: false
    sort_by_filename: false
    do_overfit: true
}

loader_semantic_kitti: {
    dataset_path: "/media/rosu/Data/data/semantic_kitti"
    // dataset_path: "/home/local/staff/rosu/data/semantic_kitti"
    autostart: false
    mode: "train" // train, test, val
    sequence: "all" //between 00 and 10 without 08, also can be "all" which means it will run through all sequences shuffled or not
    nr_clouds_to_skip: 0
    nr_clouds_to_read: -1
    cap_distance: 60
    shuffle_points: true
    do_pose: false
    normalize: false // normalize the point cloud between [-1 and 1] TAKES PRECEDENCE OVER THE POSE TRANSFORMATION
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset


    label_mngr: {
        labels_file: "/media/rosu/Data/data/semantic_kitti/colorscheme_and_labels/labels.txt"
        color_scheme_file: "/media/rosu/Data/data/semantic_kitti/colorscheme_and_labels/color_scheme.txt"
        frequency_file: "/media/rosu/Data/data/semantic_kitti/colorscheme_and_labels/frequency.txt"
        unlabeled_idx: 0
    }



    transformer: {
        random_translation_xyz_magnitude: 0.0
        random_translation_xz_magnitude: 0.0
        rotation_y_max_angle: 0.0
        random_stretch_xyz_magnitude: 0.0
        adaptive_subsampling_falloff_start: 0.0
        adaptive_subsampling_falloff_end: 0.0
        random_subsample_percentage: 0.0 //randomly removed x percent of the pointcloud
        random_mirror_x: false
        random_mirror_z: false
        random_rotation_90_degrees_y: false

        hsv_jitter:[0,0,0]

        chance_of_xyz_noise: 0.0
        xyz_noise_stddev: [0.02, 0.02, 0.02]
    }
}


loader_scannet: {
    dataset_path: "/media/rosu/Data/data/scannet"
    autostart: false
    mode: "train" // train, test, val
    nr_clouds_to_skip: 0
    // nr_clouds_to_skip: 43
    nr_clouds_to_read: -1
    max_nr_points_per_cloud: 300000
    shuffle_points: false
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset

    label_mngr: {
        labels_file: "/media/rosu/Data/data/scannet/colorscheme_and_labels/labels.txt"
        color_scheme_file: "/media/rosu/Data/data/scannet/colorscheme_and_labels/color_scheme.txt"
        frequency_file: "/media/rosu/Data/data/scannet/colorscheme_and_labels/frequency_uniform.txt"
        unlabeled_idx: 0
    }

    // one used for actual augmentation
    transformer: {
        random_translation_xyz_magnitude: 0.0
        random_translation_xz_magnitude: 5.0
        // random_translation_xz_magnitude: 0.0
        rotation_y_max_angle: 0.0
        random_stretch_xyz_magnitude: 0.0
        adaptive_subsampling_falloff_start: 0.0
        adaptive_subsampling_falloff_end: 0.0
        // random_subsample_percentage: 0.6 //randomly removed x percent of the pointcloud
        random_subsample_percentage: 0.0 //randomly removed x percent of the pointcloud
        random_mirror_x: true
        random_mirror_z: true
        random_rotation_90_degrees_y: true

        hsv_jitter: [5.0, 0.05, 0.05] //jitter in hsv space by this amount with a uniform random in [-h,h], [-s,s], [-v,v]
        // hsv_jitter: [0.0, 0.0, 0.0] //jitter in hsv space by this amount with a uniform random in [-h,h], [-s,s], [-v,v]
    }
}


loader_shapenet_img: {
    // dataset_path: "/media/rosu/Data/data/shapenet_images/ShapeNetRendering"
    // dataset_path: "/media/rosu/Data/data/shapenet_images/image"
    // dataset_depth_path: "/media/rosu/Data/data/shapenet_images/depth"

    dataset_path: "/media/rosu/Data/data/shapenet_images/renders/image"
    dataset_depth_path: "/media/rosu/Data/data/shapenet_images/renders/depth"

    // dataset_path: "/media/rosu/Data/data/shapenet_images/renders_2/image"
    // dataset_depth_path: "/media/rosu/Data/data/shapenet_images/renders_2/depth"

    // dataset_path: "/media/rosu/Data/data/shapenet_images/renders_test/image"
    // dataset_depth_path: "/media/rosu/Data/data/shapenet_images/renders_test/depth"

    restrict_to_object: "bench" //you can leave it empty to get all of them or write any of (plane, car, bench)
    nr_samples_to_skip: 0
    nr_samples_to_read: -1
    nr_imgs_to_read: -1 //nr of images for a certain scene that we want to read, a -1 means that we read all images which is around 36
    subsample_factor: 1
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    difficulty: "easy"
    load_depth: false
    load_as_shell: true
}

loader_nerf: {
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/chair"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/drums"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/ficus"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/hotdog"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/lego"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/materials"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/mic"
    dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/ship"
    subsample_factor: 1
    autostart: false
    shuffle: true
    mode: "train" //train, val, test
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    scene_scale_multiplier: 0.137
}

loader_easypbr: {
    // dataset_path: "/media/rosu/Data/data/easy_pbr_renders"
    dataset_path: "/home/rosu/work/data/easy_pbr_render"
    // object_name:"head"
    // object_name:"vase"
    object_name:"hair2D"
    subsample_factor: 1
    autostart: false
    shuffle: false
    mode: "train" //train, val, test
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // scene_scale_multiplier: 0.3
    // scene_scale_multiplier: 0.0003
    scene_scale_multiplier: {
        head: 0.3
        vase: 0.00015
        hair2D: 0.1
    }
}

loader_phenorob: {
    // dataset_path: "/media/rosu/Data/data/phenorob/data_from_david"
    dataset_path: "/media/rosu/Data/data/phenorob/data_from_david/labeledData_final"
    autostart: false
    preload: true //preload the meshes in memory which is usually quite fast if they are small, or continously read them from memory

    //params for loading
    plant_type:"maize" // select between maize, tomato
    segmentation_method: "leaf_tip" //leaf_collar or leaf_tip. Applicable only when loading maize as tomato has only one type of segmentation
    //which plants to read
    nr_plants_to_skip: 6
    nr_plants_to_read: 1 //how many plants of the selected type we should read, set to -1 to read all plants
    //which days to read
    nr_days_to_skip: 7
    nr_days_to_read: 1 //how many days to read for the selected plants, set to -1 to read all days
    //params for after reading
    shuffle_points: true
    normalize: false
    shuffle_days: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset


    // transform the data in various ways after reading
    transformer: {
        random_translation_xyz_magnitude: 0.0
        random_translation_xz_magnitude: 0.0
        rotation_y_max_angle: 0.0
        random_stretch_xyz_magnitude: 0.0
        adaptive_subsampling_falloff_start: 0.0
        adaptive_subsampling_falloff_end: 0.0
        random_subsample_percentage: 0.998 //randomly removed x percent of the pointcloud
        // random_subsample_percentage: 0.0 //randomly removed x percent of the pointcloud
        random_mirror_x: false
        random_mirror_z: false
        random_rotation_90_degrees_y: false

        hsv_jitter:[0,0,0]

        chance_of_xyz_noise: 0.0
        xyz_noise_stddev: [0.0, 0.0, 0.0]
    }

    label_mngr: {

    }

}

loader_srn: {

    dataset_path: "/media/rosu/Data/data/pixel_nerf_data/"
    object_name: "car"
    // object_name: "chair"
    mode: "train"
    get_spiral_test_else_split_train: false //the spiral in the test set looks like crap so we rather split the train set in two. Splitting occurs when we set this to false
    autostart: false


    nr_samples_to_skip: 0
    nr_samples_to_read: -1
    nr_imgs_to_read: -1 //nr of images for a certain scene that we want to read, a -1 means that we read all images which is around 36
    subsample_factor: 1
    shuffle: true
    do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    // do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    load_as_shell: true
    scene_scale_multiplier: {
        car: 0.3
        chair: 0.2
    }

}

loader_dtu: {

    dataset_path: "/media/rosu/Data/data/pixel_nerf_data/dtu_dataset/rs_dtu_4/DTU"
    mode: "train"
    restrict_to_scan_idx: -1
    autostart: false
    read_with_bg_thread: false


    subsample_factor: 4
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    load_as_shell: true
    scene_scale_multiplier: 0.2

}


loader_deep_voxels: {
    dataset_path: "/media/rosu/Data/data/deep_voxels/synthetic_scenes"
    // object_name: "armchair"
    // object_name: "bus"
    // object_name: "cube"
    object_name: "greek"
    // object_name: "shoe"
    // object_name: "vase"
    subsample_factor: 1
    autostart: false
    shuffle: true
    mode: "train" //train, val, test
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    scene_scale_multiplier: 0.15
}



ros_bag: {
    bag_path: "/media/rosu/Data/data/drz/bags/bag_mbzirc8_2020-09-30-17-52-35.bag"
    bag_args: ""

}
loader_cloud_ros: {
    cloud_topic: "/os_cloud_node/points"
    min_dist_filter: 0
    do_pose: true
    pose_file: "/media/rosu/Data/data/drz/semantic_poses/last_reg_pose_bag_mbzirc8_2020-09-30-17-52-35.txt"
    // pose_file: "/media/rosu/Data/data/drz/semantic_poses/gps_poses_bag_mbzirc8_2020-09-30-17-52-35.txt"
    pose_file_format: "tum"


    transformer: {
        random_translation_xyz_magnitude: 0.0
        random_translation_xz_magnitude: 0.0
        rotation_y_max_angle: 0.0
        random_stretch_xyz_magnitude: 0.0
        adaptive_subsampling_falloff_start: 0.0
        adaptive_subsampling_falloff_end: 0.0
        random_subsample_percentage: 0.0 //randomly removed x percent of the pointcloud
        random_mirror_x: false
        random_mirror_z: false
        random_rotation_90_degrees_y: false

        hsv_jitter:[0,0,0]

        chance_of_xyz_noise: 0.0
        xyz_noise_stddev: [0.0, 0.0, 0.0]
    }

}

loader_colmap: {
    dataset_path: "/media/rosu/Data/data/phenorob/data_from_home/christmas_thing/colmap/dense"
    subsample_factor: 32
    autostart: false
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    scene_scale_multiplier: 0.121
    load_imgs_with_transparency: false
}

loader_llff: {
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/fern"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/flower"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/fortress"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/horns"
    dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/leaves"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/orchids"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/room"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_llff_data/trex"
    subsample_factor: 4
    autostart: false
    shuffle: true
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // scene_scale_multiplier: 0.05
    scene_scale_multiplier: "auto" // can be set to a number between 0 and 1 or to "auto" which will mean that the scene will be contained in the unit cube
}

loader_blender_fb: {
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/chair"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/drums"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/ficus"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/hotdog"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/lego"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/materials"
    // dataset_path: "/media/rosu/Data/data/nerf/nerf_synthetic/nerf_synthetic/mic"
    // dataset_path: "/home/rosu/work/c_ws/src/blender_rendering_hair/output_hair_easy3"
    // dataset_path: "/home/rosu/work/c_ws/src/blender_rendering_hair/output_hair_easy4"
    // dataset_path: "/home/rosu/work/c_ws/src/blender_rendering_hair/output_hair_easy4_jpeg"
    dataset_path: "/home/rosu/work/c_ws/src/blender_rendering_hair/output_hair_easy4_png"
    pose_file_path: "/home/rosu/work/c_ws/src/blender_rendering_hair/KRT2_maya"
    orientation_and_variance_path: "/home/rosu/work/c_ws/src/blender_rendering_hair/output_hair_easy4_png_orientation_and_variance"
    // orientation_and_variance_path: ""
    subsample_factor: 64
    exposure_change: 1.0
    load_as_float: false //load files directly as a float if true, otherwise reads as rgb8u and then convert to float internally
    autostart: false
    shuffle: true
    load_as_shell: false
    mode: "all" //all, train, val, test
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    scene_scale_multiplier: 0.0005
}

loader_usc_hair: {
    dataset_path: "/home/rosu/work/data/usc_hair/hairstyles/hairstyles"
    // scalp_mesh_path: "/home/rosu/work/data/usc_hair/hairstyles/scalp2_arap.ply"
    scalp_mesh_path: "/home/rosu/work/data/usc_hair/hair_recon/scalp_flame.ply"
    autostart: false
    mode: "train" // train, test, val
    nr_clouds_to_skip: 0
    nr_clouds_to_read: -1
    // nr_clouds_to_read: 1
    // nr_clouds_to_read: 10
    // nr_clouds_to_read: 150
    percentage_strand_drop: 0.9 // we randomly drop strand with this probability, range is [0,1]. 0 means we drop no strabds
    // percentage_strand_drop: 0.0 // we randomly drop strand with this probability, range is [0,1]. 0 means we drop no strabds
    load_only_strand_with_idx: -1
    shuffle: true
    load_buffered: true //if we load buffered we only keep a ringbuffer of meshes in the loader. If it's not buffered we persistently keep all which means is faster to recover
    // load_buffered: false
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    // do_overfit: true //return only one of the samples the whole time, concretely the first sample in the dataset

    augment_per_strand: true
    augment_in_tbn_space: true
    // augment_hair_bounce: true
    transformer: {
        random_translation_xyz_magnitude: [0, 0, 0]
        rotation_x_max_angle: 0
        rotation_y_max_angle: 0
        rotation_z_max_angle: 0
        random_stretch_xyz_magnitude: [0.0, 0.0, 3.0]
        adaptive_subsampling_falloff_start: 0.0
        adaptive_subsampling_falloff_end: 0.0
        random_subsample_percentage: 0.0 //randomly removed x percent of the pointcloud
        random_mirror_x: false
        random_mirror_y: false
        random_mirror_z: false
        random_rotation_90_degrees_y: false

        hsv_jitter:[0,0,0]

        chance_of_xyz_noise: 0.0
        xyz_noise_stddev: [0.02, 0.02, 0.02]
    }

}

loader_phenorob_cp1: {
    dataset_path: "/media/rosu/Data/data/phenorob/days_on_field"
    scan_date: "2021_05_20_incomplete_just_9" //cal also be left empty to read all the dates
    // scan_idx: 9 //can be set to -1 to read all scans


    rotation_alignment_degrees: -130
    transform_to_easypbr_world: true

    subsample_factor: 8
    autostart: false
    shuffle: false
    load_as_shell: true
    mode: "all" //all, train, val, test
    do_overfit: false //return only one of the samples the whole time, concretely the first sample in the dataset
    scene_scale_multiplier: 1.0
}




visualization: {
    show_gui: true

    subsample_factor: 1
    enable_culling: false

    cam: {
        fov: 60 //can be a float value (fov: 30.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        near: 0.3 //can be a float value (near: 0.01) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        far: "auto" //can be a float value (far: 10,0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        exposure: 1.0 //can be floar or "auto"
    }

    scene: {
        floor_visible: true
        floor_metric: true
    }


    ssao: {
        auto_settings: false
        enable_ssao: false
        ao_downsample: 0
        kernel_radius: "auto" //can be a float value (kernel_radius: 10,0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
        ao_power: 4
        ao_blur_sigma_spacial: 2.0
        ao_blur_sigma_depth: 0.0001
    }

    bloom: {
        enable_bloom: false
        threshold: 0.85
        mip_map_lvl: 1
        blur_iters: 3
    }

    edl: {
        auto_settings: false
        enable_edl_lighting: true
        edl_strength: 8.0
    }

    background:{
        show_background_img: false
        background_img_path: ""
    }

    ibl: {
        enable_ibl: false
        show_environment_map: false
        // environment_map_path: "/media/rosu/Data/data/sibl/Desert_Highway/Road_to_MonumentValley_Ref.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/Footprint_Court/Footprint_Court_2k.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/Circus_Backstage/Circus_Backstage_3k.hdr"
        // environment_map_path: "/media/rosu/Data/data/sibl/canary_wharf_4k.hdr"
        environment_map_path: "sibl/Barcelona_Rooftops/Barce_Rooftop_C_3k.hdr"
        // environment_cubemap_resolution: 2048
        environment_cubemap_resolution: 512
        irradiance_cubemap_resolution: 32
        prefilter_cubemap_resolution: 128
        brdf_lut_resolution: 512
    }

    lights:{
        nr_spot_lights: 0
        spot_light_0: {
            power: "auto" //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 2048
        }
        spot_light_1: {
            power: "auto" //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 1024
        }
        spot_light_2: {
            power: "auto"  //can be a float value (power: 1.0) or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            color: "auto" //can be a vector of rgb [1.0, 1.0, 0.5] or can be set to "auto" so that it's set automatically when the first mesh is added to the scene
            create_shadow: true
            shadow_map_resolution: 1024
        }
    }

}
